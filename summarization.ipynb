{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agolla2/Summarization-OpenAI/blob/main/summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4oj8necT0FY"
      },
      "source": [
        "## Text Summarization Using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-YFYVjoT0FZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "open_api_key=\"OpenAI API Key\"\n",
        "os.environ[\"OPENAI_API_KEY\"]=open_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Za0Sz1bT0Fa"
      },
      "outputs": [],
      "source": [
        "## Basic Prompt Summarization\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import(\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-W_2R2vGT0Fa"
      },
      "outputs": [],
      "source": [
        "speech=\"\"\"\n",
        "People across the country, involved in government, political, and social activities, are dedicating their time to make the ‘Viksit Bharat Sankalp Yatra’ (Developed India Resolution Journey) successful. Therefore, as a Member of Parliament, it was my responsibility to also contribute my time to this program. So, today, I have come here just as a Member of Parliament and your ‘sevak’, ready to participate in this program, much like you.\n",
        "\n",
        "In our country, governments have come and gone, numerous schemes have been formulated, discussions have taken place, and big promises have been made. However, my experience and observations led me to believe that the most critical aspect that requires attention is ensuring that the government’s plans reach the intended beneficiaries without any hassles. If there is a ‘Pradhan Mantri Awas Yojana’ (Prime Minister’s housing scheme), then those who are living in jhuggis and slums should get their houses. And he should not need to make rounds of the government offices for this purpose. The government should reach him. Since you have assigned this responsibility to me, about four crore families have got their ‘pucca’ houses. However, I have encountered cases where someone is left out of the government benefits. Therefore, I have decided to tour the country again, to listen to people’s experiences with government schemes, to understand whether they received the intended benefits, and to ensure that the programs are reaching everyone as planned without paying any bribes. We will get the real picture if we visit them again. Therefore, this ‘Viksit Bharat Sankalp Yatra’ is, in a way, my own examination. I want to hear from you and the people across the country whether what I envisioned and the work I have been doing aligns with reality and whether it has reached those for whom it was meant.\n",
        "\n",
        "It is crucial to check whether the work that was supposed to happen has indeed taken place. I recently met some individuals who utilized the Ayushman card to get treatment for serious illnesses. One person met with a severe accident, and after using the card, he could afford the necessary operation, and now he is recovering well. When I asked him, he said: “How could I afford this treatment? Now that there is the Ayushman card, I mustered courage and underwent an operation. Now I am perfectly fine.”  Such stories are blessings to me.\n",
        "\n",
        "The bureaucrats, who prepare good schemes, expedite the paperwork and even allocate funds, also feel satisfied that 50 or 100 people who were supposed to get the funds have got it. The funds meant for a thousand villages have been released. But their job satisfaction peaks when they hear that their work has directly impacted someone’s life positively. When they see the tangible results of their efforts, their enthusiasm multiplies. They feel satisfied. Therefore, ‘Viksit Bharat Sankalp Yatra’ has had a positive impact on government officers. It has made them more enthusiastic about their work, especially when they witness the tangible benefits reaching the people. Officers now feel satisfied with their work, saying, “I made a good plan, I created a file, and the intended beneficiaries received the benefits.” When they find that the money has reached a poor widow under the Jeevan Jyoti scheme and it was a great help to her during her crisis, they realise that they have done a good job. When a government officer listens to such stories, he feels very satisfied.\n",
        "\n",
        "There are very few who understand the power and impact of the ‘Viksit Bharat Sankalp Yatra’. When I hear people connected to bureaucratic circles talking about it, expressing their satisfaction, it resonates with me. I’ve heard stories where someone suddenly received 2 lakh rupees after the death of her husband, and a sister mentioned how the arrival of gas in her home transformed her lives. The most significant aspect is when someone says that the line between rich and poor has vanished. While the slogan ‘Garibi Hatao’ (Remove Poverty) is one thing, but the real change happens when a person says, “As soon as the gas stove came to my house, the distinction between poverty and affluence disappeared.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BizKbsoT0Fb",
        "outputId": "e0a5fab6-a851-4f8c-f518-6a6790810657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-9f3feaaee362>:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm=ChatOpenAI(model_name='gpt-3.5-turbo')\n"
          ]
        }
      ],
      "source": [
        "chat_messages=[\n",
        "    SystemMessage(content='You are an expert assistant with expertize in summarizing speeches'),\n",
        "    HumanMessage(content=f'Please provide a short and concise summary of the following speech:\\n TEXT: {speech}')\n",
        "]\n",
        "\n",
        "llm=ChatOpenAI(model_name='gpt-3.5-turbo')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oyugEF6T0Fc",
        "outputId": "3f054fd1-261b-486b-81e4-34eb2bf2e2bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "866"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "##total tokens\n",
        "llm.get_num_tokens(speech)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-Nf6mueT0Fc",
        "outputId": "15bba19e-2798-433f-c932-2c8c46c385e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The speech highlights the importance of ensuring government schemes reach the intended beneficiaries without any difficulties. The speaker, a Member of Parliament, discusses the impact of the 'Viksit Bharat Sankalp Yatra' in ensuring effective implementation of programs. Through personal anecdotes, the speaker emphasizes the significance of tangible results and positive impact on people's lives. The speech underscores the role of bureaucrats in making a difference and the satisfaction derived from seeing the direct benefits of their efforts. Overall, the 'Viksit Bharat Sankalp Yatra' aims to bridge the gap between the government's plans and their actual implementation, leading to tangible improvements in the lives of citizens.\n"
          ]
        }
      ],
      "source": [
        "print(llm(chat_messages).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6djXNr6T0Fc"
      },
      "source": [
        "## Prompt Templates Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDM3qrwiT0Fc"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSfW4xe7T0Fd"
      },
      "outputs": [],
      "source": [
        "generic_template='''\n",
        "Write a summary of the following speech:\n",
        "Speech : `{speech}`\n",
        "Translate the precise summary to {language}.\n",
        "\n",
        "'''\n",
        "prompt=PromptTemplate(\n",
        "    input_variables=['speech','language'],\n",
        "    template=generic_template\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "h3spaX0sT0Fd",
        "outputId": "8c987f27-dc76-42b5-8dd2-3052a14e62ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWrite a summary of the following speech:\\nSpeech : `\\nPeople across the country, involved in government, political, and social activities, are dedicating their time to make the ‘Viksit Bharat Sankalp Yatra’ (Developed India Resolution Journey) successful. Therefore, as a Member of Parliament, it was my responsibility to also contribute my time to this program. So, today, I have come here just as a Member of Parliament and your ‘sevak’, ready to participate in this program, much like you.\\n\\nIn our country, governments have come and gone, numerous schemes have been formulated, discussions have taken place, and big promises have been made. However, my experience and observations led me to believe that the most critical aspect that requires attention is ensuring that the government’s plans reach the intended beneficiaries without any hassles. If there is a ‘Pradhan Mantri Awas Yojana’ (Prime Minister’s housing scheme), then those who are living in jhuggis and slums should get their houses. And he should not need to make rounds of the government offices for this purpose. The government should reach him. Since you have assigned this responsibility to me, about four crore families have got their ‘pucca’ houses. However, I have encountered cases where someone is left out of the government benefits. Therefore, I have decided to tour the country again, to listen to people’s experiences with government schemes, to understand whether they received the intended benefits, and to ensure that the programs are reaching everyone as planned without paying any bribes. We will get the real picture if we visit them again. Therefore, this ‘Viksit Bharat Sankalp Yatra’ is, in a way, my own examination. I want to hear from you and the people across the country whether what I envisioned and the work I have been doing aligns with reality and whether it has reached those for whom it was meant.\\n\\nIt is crucial to check whether the work that was supposed to happen has indeed taken place. I recently met some individuals who utilized the Ayushman card to get treatment for serious illnesses. One person met with a severe accident, and after using the card, he could afford the necessary operation, and now he is recovering well. When I asked him, he said: “How could I afford this treatment? Now that there is the Ayushman card, I mustered courage and underwent an operation. Now I am perfectly fine.”  Such stories are blessings to me.\\n\\nThe bureaucrats, who prepare good schemes, expedite the paperwork and even allocate funds, also feel satisfied that 50 or 100 people who were supposed to get the funds have got it. The funds meant for a thousand villages have been released. But their job satisfaction peaks when they hear that their work has directly impacted someone’s life positively. When they see the tangible results of their efforts, their enthusiasm multiplies. They feel satisfied. Therefore, ‘Viksit Bharat Sankalp Yatra’ has had a positive impact on government officers. It has made them more enthusiastic about their work, especially when they witness the tangible benefits reaching the people. Officers now feel satisfied with their work, saying, “I made a good plan, I created a file, and the intended beneficiaries received the benefits.” When they find that the money has reached a poor widow under the Jeevan Jyoti scheme and it was a great help to her during her crisis, they realise that they have done a good job. When a government officer listens to such stories, he feels very satisfied.\\n\\nThere are very few who understand the power and impact of the ‘Viksit Bharat Sankalp Yatra’. When I hear people connected to bureaucratic circles talking about it, expressing their satisfaction, it resonates with me. I’ve heard stories where someone suddenly received 2 lakh rupees after the death of her husband, and a sister mentioned how the arrival of gas in her home transformed her lives. The most significant aspect is when someone says that the line between rich and poor has vanished. While the slogan ‘Garibi Hatao’ (Remove Poverty) is one thing, but the real change happens when a person says, “As soon as the gas stove came to my house, the distinction between poverty and affluence disappeared.\\n`\\nTranslate the precise summary to Hindi.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "prompt.format(speech=speech,language='Hindi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upYOdKO7T0Fd"
      },
      "outputs": [],
      "source": [
        "complete_prompt=prompt.format(speech=speech,language='Hindi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e-DYYPRT0Fd",
        "outputId": "a385ea2a-a06f-4873-c9ea-5bd551cdee3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "885"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "llm.get_num_tokens(complete_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCsAf33vT0Fd",
        "outputId": "35df65a2-e54f-4742-b873-833f609faf19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-d99181f59cbe>:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
            "<ipython-input-14-d99181f59cbe>:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  summary=llm_chain.run({'speech':speech,'language':'hindi'})\n"
          ]
        }
      ],
      "source": [
        "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
        "summary=llm_chain.run({'speech':speech,'language':'hindi'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "lyFCoFjvT0Fd",
        "outputId": "7c5930e0-5e75-4451-bbfc-1864011bea57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'भारत भीषण इच्छाशक्ति यात्रा\\' को सफल बनाने के लिए लोग पूरे देश में सरकार, राजनीतिक और सामाजिक गतिविधियों में शामिल हैं। इसलिए, संसद के सदस्य के रूप में, मेरा यह कर्तव्य भी इस कार्यक्रम में समय देना था। मैं आज यहां सिर्फ संसद के सदस्य और आपके ‘सेवक’ के रूप में आया हूं, जैसे कि आप भी। मुझे लगता है कि सरकार की योजनाएं जो लोगों तक पहुंचनी चाहिए, उन्हें बिना किसी परेशानी के पहुंचना बहुत महत्वपूर्ण है। मैंने देखा है कि चार करोड़ परिवारों को उनके \\'पुक्के\\' मकान मिल गए हैं। हालांकि, मुझे ऐसे मामले भी आए हैं जहां किसी को सरकारी लाभ से वंचित छोड़ दिया गया है। इसलिए, मैंने देश भर में फिर से यात्रा करने का निर्णय लिया है, लोगों के साथ बातचीत करने के लिए, समझने के लिए कि क्या उन्हें उसे लाभ पहुंचा या योजनाएं सभी के पास जैसा था, और सुनिश्चित करने के लिए कि कोई भी रिश्वत न देकर योजनाएं सभी तक पहुंच रही हैं। यह \\'विकसित भारत संकल्प यात्रा\\' मेरा अपना परीक्षण है। मैं चाहता हूं कि मैं और देशभर के लोग जानें कि मेरी योजना और मेरा काम वास्तविकता के साथ मेल खाता है या नहीं, और क्या इसे उन लोगों तक पहुंचाया गया है जिनके लिए यह था।\\n\\nयह जांच करना महत्वपूर्ण है कि जो काम होना चाहिए था, क्या वास्तव में हुआ है। एक व्यक्ति ने ऐयुष्मान कार्ड का उपयोग करके गंभीर बीमारियों के इलाज के लिए की थी। जब मैंने पूछा, तो उसने कहा, \"मैं इस उपचार को कैसे संभाल सकता? अब जब ऐयुष्मान कार्ड है, तो मैंने हिम्मत जुटाई और ऑपरेशन करवाया। अब मैं पूरी तरह सही हूं।\" ऐसी कहानियां मुझे आशीर्वाद मानी जाती हैं।\\n\\nजब बदले बनाने वाले, जो अच्छी योजनाएं तैयार करते हैं, दस्तावेजी कार्य को तेजी से प्रारंभ करते हैं और धन का आवंटन भी करते हैं, उन्हें भी खुशी होती है कि जिन लोगों को धन प्राप्त होना चाहिए था, उन्हें मिल गया है। यह \\'विकसित भारत संकल्प यात्रा\\' ने सरकारी अधिकारियों पर सकारात्मक प्रभाव डाला है। यह उन्हें अधिक उत्साही बनाता है कि वे उन लोगों तक पहुंचने वाले वास्तविक लाभ देखते हैं। अधिकारी अब अपने काम से संतुष्ट महसूस करते हैं, कहते हैं, \"मैंने एक अच्छी योजना बनाई, मैंने एक फाइल बनाई, और उन्हें लाभ प्राप्त हुआ है।\" जब उन्हें यह मालूम होता है कि एक गरीब विधवा को जीवन ज्योति योजना के तहत पैसा मिला है और यह उसकी संकट के समय में बहुत मददगार था, तो उन्हें यह लगता है कि उन्होंने अच्छा काम किया है।\\n\\nबहुत कम हैं जो \\'विकसित भारत संकल्प यात्रा\\' की शक्ति और प्रभाव को समझते हैं। जब मैं ब्यूरोक्रेटिक वर्ग से जुड़े लोगों से इसके बारे में बातें सुनता हूं, उनकी संतुष्टि के अभिव्यक्ति से मुझे अभिलाषा होती है। मैंने कहानियां सुनी हैं जहां किसी को अचानक अपने पति की मौत के बाद 2 लाख रुपए मिले, और एक बहन ने किस तरह से घर में गैस के आने से उनकी जिंदगी में परिवर्तन आया। सबसे महत्वपूर्ण बात यह है कि जब कोई कहता है कि गरीबी और समृद्धि के बीच की रेखा गायब हो गई है। जबकि नारा \\'गरीबी हटाओ\\' एक बात है, लेकिन वास्तविक परिवर्तन तब होता है जब कोई व्यक्ति कहता है, \"मेरे घर में गैस स्टोव आने के बाद, गरीबी और समृद्धि के बीच का अंत हो गया है।\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI1eWgNs7bMz",
        "outputId": "6c600729-e585-49d0-f355-6d499317ee9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3usYRpOT0Fd"
      },
      "source": [
        "## StuffDocumentChain Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wOXiN7CT0Fd"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-1ZenEKT0Fd"
      },
      "outputs": [],
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('Akhil_Golla_Resume8.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhQoK4cVT0Fe"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jbIZjhzMT0Fe",
        "outputId": "faa51337-e158-4cac-9bab-1fb1d32a4de0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Akhil Golla\\n404-934-1623 |akhilgolla08@gmail.com |LinkedIn |GitHub |Atlanta, GA (Open to relocation)\\nSummary\\nCurrently working as a Research Data Analyst for the Georgia State University Cybersecurity Research Group,\\nwith prior experience as a Data Scientist in healthcare and 4+ years in cybersecurity, fraud analysis,\\nsales forecasting, predictive modeling, Generative AI (Gen AI) , and Large Language Models (LLMs) .\\nImmediate joiner seeking data science or analyst roles to leverage my expertise in solving real-world\\nproblems through data-driven solutions.\\nEducation\\nGeorgia State University Atlanta, GA\\nMaster of Science in Information Systems, Big Data Analytics Jan 2023 – Dec 2023\\nOsmania Unversity Hyderabad, India\\nBachelor of Engineering, Electronics Jun 2016 – Sept 2020\\nTechnical Skills\\nProgramming Languages : Python, SQL, R, Pyspark.\\nPython Libraries : Pandas, NumPy, Scikit-learn, TensorFlow, Keras, PyTorch, NLTK, Gensim, Matplotlib, Seaborn.\\nMachine Learning : Linear-Logistic Regression, Decision Trees, Support Vector Machines, KNN, Random Forest,\\nClustering (K-means), Ensemble Modelling Techniques (Boosting, Stacking, Bagging), XGBoost, LightGBM, AdaBoost,\\nDeep Learning, Large Language Models (LLM), Langchain, Transformers (BERT, BART, GPT), Neural\\nNetworks,LSTM, CNN, RNN, NLP, SARIMA, ARIMA, Prophet, OCR.\\nData Visualization Tools : Tableau, Microsoft Power BI, DOMO.\\nDatabases : Microsoft SQL Server, MySQL, Snowflake.\\nCloud Technologies : Databricks, AWS EC2, IAM, S3, Lambda, SageMaker, Glue.\\nDeveloper Tools : Jupyter Notebook, Databricks, Alteryx, Git, VScode, Anaconda, Eclipse, Docker, Azure Data\\nStudio, Salesforce.\\nExperience\\nResearch Data Analyst Feb 2023 – Present\\nEvidence-Based Cybersecurity Research Group – Georgia State University Atlanta, GA\\n•Developed and maintained Python scripts using the Beautiful Soup library for automating data collection by\\nweb scraping multiple illicit Telegram channels, improving efficiency and saving 75% of time compared to manual\\nprocesses by enabling automated and reusable scraping workflows.\\n•Analyzed unstructured chat data from multiple channels and created impactful visualizations in Tableau ,\\nenabling stakeholders to make informed decisions 50% faster and improving operational efficiency.\\n•Designed and implemented an automated BERT-based classifier to detect theft-related and illegal transactions\\nfrom Telegram and darknet data, achieving over 90% accuracy and contributing to public reporting of savings\\nexceeding $10 million .\\n•Created an automated chatbot using Python ,Selenium , and Wit AI to generate automatic responses across 20\\nteen chat rooms, enabling data collection for an online honeypot awareness project, which contributed to\\nsafeguarding millions of teens from potential online threats.\\n•Leveraged NLP techniques such as TF-IDF andsentiment analysis to extract key insights, popular content,\\nand contextual patterns from Telegram channels, enhancing channel dynamics understanding and enabling\\nactionable insights. This analysis improved decision-making efficiency by 40% for stakeholders addressing critical\\nchannel activities.\\n•Designed and implemented an automated Python solution utilizing OCR (Optical Character Recognition) to\\ndetect and eliminate image duplication, achieving a 50% improvement in analysis efficiency. Integrated the\\nsolution with the Dropbox API to streamline data management and ensure seamless processing.Data Scientist March 2024 – November 2024\\nTeleSpecialists LLC (Hospitals & Health Care) Atlanta, GA\\n•Developed, scaled, and deployed a time series forecasting model using SARIMA to predict future case\\nvolumes from each facility and state. This enabled the company to proactively plan resources and optimize\\nphysician scheduling, leading to an 80% increase in operational efficiency by accurately forecasting volumes in\\nadvance.\\n•Built an LSTM neural network ML model to forecast physician scheduling based on predicted case volumes,\\noptimizing resource allocation, reducing scheduling conflicts, and saving $1 million annually by preventing\\noverpayments to underutilized physicians.\\n•Worked on developing a clinical note summarization system leveraging the BioBART large language\\nmodel (LLM) to process over 1 million cases , significantly reducing the time required for physicians to revisit\\nand review cases, improving workflow efficiency and enhancing patient care outcomes.\\n•Created dynamic Tableau dashboards to visualize key metrics across departments including Physician\\nCredentialing, Marketing, Medical Staff Division, Onboarding, IT, and HR. These dashboards delivered actionable\\ninsights, enhancing decision-making processes by 40% and improving operational outcomes.\\n•Established and managed connections between Tableau ,Salesforce ,Five9 , and SQL Server , streamlining data\\nflow and enabling real-time access to processed data. This reduced reporting delays by 50% , enhancing analysis\\nspeed and efficiency.\\n•Utilized Azure Data Studio to write SQL queries , extracting and preparing datasets for dashboards and\\nreports. This improved data accuracy and reporting timelines by 30% across multiple departments.\\n•Designed and maintained ETL pipelines to integrate patient case data with key metrics seamlessly, enabling\\naccurate analysis and reporting. This streamlined hospital decision-making processes and reduced manual data\\nprocessing efforts by 45% .\\nData Science Intern June 2023 – December 2023\\nElevance Health Inc. (formerly Anthem Inc.) Atlanta, GA\\n•Developed a claim price prediction model using Random Forest andDecision Tree algorithms with\\nensemble stacking , achieving an R²score of 0.92 . This enhanced accuracy helped identify and mitigate claim\\ndiscrepancies, reducing financial losses by 50% and saving millions annually .\\n•Maintained and managed machine learning models deployed in Docker environments , resolving\\nenvironment-related issues and ensuring consistent model performance and reliability across production systems.\\n•Improved model transparency by implementing SHAP andLIME for interpretability, enabling seamless\\ncommunication of insights to non-technical stakeholders and fostering informed decision-making.\\n•Optimized data processing efficiency by 40% through advanced SQL queries inSnowflake , enabling faster data\\nmanagement workflows and enhancing training processes for machine learning models.\\n•Created interactive Tableau dashboards to track and analyze claim trends, visualize key performance metrics,\\nand uncover patterns in claim overpayments. These dashboards empowered leadership to make data-driven\\ndecisions and adopt more strategic claims management practices.\\nAssociate Data Scientist January 2021 – December 2022\\nAccenture Solutions Hyderabad, India\\n•Increased monthly sales by 25% by developing regression machine learning models to accurately predict crude oil\\ndemand, leveraging Python’s machine learning libraries to analyze market trends and forecast pricing\\nstrategies.\\n•Enhanced stakeholder decision-making by creating actionable Tableau dashboards that visualized customer\\nbehavior and sales trends, improving marketing and pricing strategies for key products.\\n•Drove success in product launches by setting goals, forecasting outcomes, and tracking key performance\\nmetrics , ensuring consistent improvement in market trends analysis.\\n•Streamlined data analysis workflows by building ETL pipelines using Alteryx , seamlessly integrating product\\ndata with sales metrics, and enabling critical insights during stakeholder presentations.\\nData Science Intern October 2020 – December 2020\\nSplash Business Intelligence Hyderabad, India\\n•Reduced manual effort by 75% through the automation of critical data processing tasks using shell/bash\\nscripting , significantly improving operational efficiency.\\n•Boosted data quality and availability by 30% by preprocessing large datasets using MySQL , including data\\ncleaning, validation, and transformation, ensuring faster and more accurate insights for the data science team to act\\nupon.Projects\\nText Summarization and Analysis with LangChain (LLM)\\n•Enhanced document summarization efficiency by40% by leveraging advanced language model algorithms\\nintegrated with LangChain , enabling faster processing and analysis of large-scale text datasets.\\nPredictive Analytics on Stack Exchange Data\\n•Improved user engagement by 30% through the implementation of a Random Forest predictive model that\\naccurately forecasted post responses and view counts, providing actionable insights to optimize content visibility.\\nTelecom Customer Churn Prediction\\n•Achieved 94.33% accuracy in predicting customer churn by analyzing over 7,000 records using advanced\\nmachine learning techniques , including decision trees, random forests, and gradient boosting, resulting in\\ntargeted retention strategies and improved customer satisfaction.\\nCertifications & Achievements\\n•Completed certifications on Visualizing Data with Power BI (Udemy), Python for Data Science and\\nMachine Learning (Udemy), SQL Bootcamp (Udemy), and NLP (Udemy).\\n•Recognized with the “Rookie Star” award for outstanding performance at Accenture Solutions.\\n•Achieved DOMO BI Tool Student Certification , demonstrating proficiency in business intelligence tools.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hELbVHGT0Fe"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoBKG2seT0Fe",
        "outputId": "446c1345-bad3-4c56-9744-61b14bb2f414"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='Akhil Golla\\n404-934-1623 |akhilgolla08@gmail.com |LinkedIn |GitHub |Atlanta, GA (Open to relocation)\\nSummary\\nCurrently working as a Research Data Analyst for the Georgia State University Cybersecurity Research Group,\\nwith prior experience as a Data Scientist in healthcare and 4+ years in cybersecurity, fraud analysis,\\nsales forecasting, predictive modeling, Generative AI (Gen AI) , and Large Language Models (LLMs) .\\nImmediate joiner seeking data science or analyst roles to leverage my expertise in solving real-world\\nproblems through data-driven solutions.\\nEducation\\nGeorgia State University Atlanta, GA\\nMaster of Science in Information Systems, Big Data Analytics Jan 2023 – Dec 2023\\nOsmania Unversity Hyderabad, India\\nBachelor of Engineering, Electronics Jun 2016 – Sept 2020\\nTechnical Skills\\nProgramming Languages : Python, SQL, R, Pyspark.\\nPython Libraries : Pandas, NumPy, Scikit-learn, TensorFlow, Keras, PyTorch, NLTK, Gensim, Matplotlib, Seaborn.\\nMachine Learning : Linear-Logistic Regression, Decision Trees, Support Vector Machines, KNN, Random Forest,\\nClustering (K-means), Ensemble Modelling Techniques (Boosting, Stacking, Bagging), XGBoost, LightGBM, AdaBoost,\\nDeep Learning, Large Language Models (LLM), Langchain, Transformers (BERT, BART, GPT), Neural\\nNetworks,LSTM, CNN, RNN, NLP, SARIMA, ARIMA, Prophet, OCR.\\nData Visualization Tools : Tableau, Microsoft Power BI, DOMO.\\nDatabases : Microsoft SQL Server, MySQL, Snowflake.\\nCloud Technologies : Databricks, AWS EC2, IAM, S3, Lambda, SageMaker, Glue.\\nDeveloper Tools : Jupyter Notebook, Databricks, Alteryx, Git, VScode, Anaconda, Eclipse, Docker, Azure Data\\nStudio, Salesforce.\\nExperience\\nResearch Data Analyst Feb 2023 – Present\\nEvidence-Based Cybersecurity Research Group – Georgia State University Atlanta, GA\\n•Developed and maintained Python scripts using the Beautiful Soup library for automating data collection by\\nweb scraping multiple illicit Telegram channels, improving efficiency and saving 75% of time compared to manual\\nprocesses by enabling automated and reusable scraping workflows.\\n•Analyzed unstructured chat data from multiple channels and created impactful visualizations in Tableau ,\\nenabling stakeholders to make informed decisions 50% faster and improving operational efficiency.\\n•Designed and implemented an automated BERT-based classifier to detect theft-related and illegal transactions\\nfrom Telegram and darknet data, achieving over 90% accuracy and contributing to public reporting of savings\\nexceeding $10 million .\\n•Created an automated chatbot using Python ,Selenium , and Wit AI to generate automatic responses across 20\\nteen chat rooms, enabling data collection for an online honeypot awareness project, which contributed to\\nsafeguarding millions of teens from potential online threats.\\n•Leveraged NLP techniques such as TF-IDF andsentiment analysis to extract key insights, popular content,\\nand contextual patterns from Telegram channels, enhancing channel dynamics understanding and enabling\\nactionable insights. This analysis improved decision-making efficiency by 40% for stakeholders addressing critical\\nchannel activities.\\n•Designed and implemented an automated Python solution utilizing OCR (Optical Character Recognition) to\\ndetect and eliminate image duplication, achieving a 50% improvement in analysis efficiency. Integrated the\\nsolution with the Dropbox API to streamline data management and ensure seamless processing.Data Scientist March 2024 – November 2024\\nTeleSpecialists LLC (Hospitals & Health Care) Atlanta, GA\\n•Developed, scaled, and deployed a time series forecasting model using SARIMA to predict future case\\nvolumes from each facility and state. This enabled the company to proactively plan resources and optimize\\nphysician scheduling, leading to an 80% increase in operational efficiency by accurately forecasting volumes in\\nadvance.\\n•Built an LSTM neural network ML model to forecast physician scheduling based on predicted case volumes,\\noptimizing resource allocation, reducing scheduling conflicts, and saving $1 million annually by preventing\\noverpayments to underutilized physicians.\\n•Worked on developing a clinical note summarization system leveraging the BioBART large language\\nmodel (LLM) to process over 1 million cases , significantly reducing the time required for physicians to revisit\\nand review cases, improving workflow efficiency and enhancing patient care outcomes.\\n•Created dynamic Tableau dashboards to visualize key metrics across departments including Physician\\nCredentialing, Marketing, Medical Staff Division, Onboarding, IT, and HR. These dashboards delivered actionable\\ninsights, enhancing decision-making processes by 40% and improving operational outcomes.\\n•Established and managed connections between Tableau ,Salesforce ,Five9 , and SQL Server , streamlining data\\nflow and enabling real-time access to processed data. This reduced reporting delays by 50% , enhancing analysis\\nspeed and efficiency.\\n•Utilized Azure Data Studio to write SQL queries , extracting and preparing datasets for dashboards and\\nreports. This improved data accuracy and reporting timelines by 30% across multiple departments.\\n•Designed and maintained ETL pipelines to integrate patient case data with key metrics seamlessly, enabling\\naccurate analysis and reporting. This streamlined hospital decision-making processes and reduced manual data\\nprocessing efforts by 45% .\\nData Science Intern June 2023 – December 2023\\nElevance Health Inc. (formerly Anthem Inc.) Atlanta, GA\\n•Developed a claim price prediction model using Random Forest andDecision Tree algorithms with\\nensemble stacking , achieving an R²score of 0.92 . This enhanced accuracy helped identify and mitigate claim\\ndiscrepancies, reducing financial losses by 50% and saving millions annually .\\n•Maintained and managed machine learning models deployed in Docker environments , resolving\\nenvironment-related issues and ensuring consistent model performance and reliability across production systems.\\n•Improved model transparency by implementing SHAP andLIME for interpretability, enabling seamless\\ncommunication of insights to non-technical stakeholders and fostering informed decision-making.\\n•Optimized data processing efficiency by 40% through advanced SQL queries inSnowflake , enabling faster data\\nmanagement workflows and enhancing training processes for machine learning models.\\n•Created interactive Tableau dashboards to track and analyze claim trends, visualize key performance metrics,\\nand uncover patterns in claim overpayments. These dashboards empowered leadership to make data-driven\\ndecisions and adopt more strategic claims management practices.\\nAssociate Data Scientist January 2021 – December 2022\\nAccenture Solutions Hyderabad, India\\n•Increased monthly sales by 25% by developing regression machine learning models to accurately predict crude oil\\ndemand, leveraging Python’s machine learning libraries to analyze market trends and forecast pricing\\nstrategies.\\n•Enhanced stakeholder decision-making by creating actionable Tableau dashboards that visualized customer\\nbehavior and sales trends, improving marketing and pricing strategies for key products.\\n•Drove success in product launches by setting goals, forecasting outcomes, and tracking key performance\\nmetrics , ensuring consistent improvement in market trends analysis.\\n•Streamlined data analysis workflows by building ETL pipelines using Alteryx , seamlessly integrating product\\ndata with sales metrics, and enabling critical insights during stakeholder presentations.\\nData Science Intern October 2020 – December 2020\\nSplash Business Intelligence Hyderabad, India\\n•Reduced manual effort by 75% through the automation of critical data processing tasks using shell/bash\\nscripting , significantly improving operational efficiency.\\n•Boosted data quality and availability by 30% by preprocessing large datasets using MySQL , including data\\ncleaning, validation, and transformation, ensuring faster and more accurate insights for the data science team to act\\nupon.Projects\\nText Summarization and Analysis with LangChain (LLM)\\n•Enhanced document summarization efficiency by40% by leveraging advanced language model algorithms\\nintegrated with LangChain , enabling faster processing and analysis of large-scale text datasets.\\nPredictive Analytics on Stack Exchange Data\\n•Improved user engagement by 30% through the implementation of a Random Forest predictive model that\\naccurately forecasted post responses and view counts, providing actionable insights to optimize content visibility.\\nTelecom Customer Churn Prediction\\n•Achieved 94.33% accuracy in predicting customer churn by analyzing over 7,000 records using advanced\\nmachine learning techniques , including decision trees, random forests, and gradient boosting, resulting in\\ntargeted retention strategies and improved customer satisfaction.\\nCertifications & Achievements\\n•Completed certifications on Visualizing Data with Power BI (Udemy), Python for Data Science and\\nMachine Learning (Udemy), SQL Bootcamp (Udemy), and NLP (Udemy).\\n•Recognized with the “Rookie Star” award for outstanding performance at Accenture Solutions.\\n•Achieved DOMO BI Tool Student Certification , demonstrating proficiency in business intelligence tools.')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "docs = [Document(page_content=text)]\n",
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj6nBikCT0Fe"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZliuIW-T0Fe"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.docstore.document import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8aLoIDuT0Fe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxBVFiNTT0Fe"
      },
      "outputs": [],
      "source": [
        "template = '''Write a concise and short summary of the following speech.\n",
        "Speech: `{text}`\n",
        "'''\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['text'],\n",
        "    template=template\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHVi_y6wT0Fe"
      },
      "outputs": [],
      "source": [
        "chain = load_summarize_chain(\n",
        "    llm,\n",
        "    chain_type='stuff',\n",
        "    prompt=prompt,\n",
        "    verbose=False\n",
        ")\n",
        "output_summary = chain.run(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "cAJVDCOcT0Ff",
        "outputId": "180326db-076f-4d4c-9412-6c321a5b3f32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Akhil Golla is a Research Data Analyst with experience in healthcare, cybersecurity, fraud analysis, and predictive modeling. He is skilled in Python, SQL, R, and various machine learning techniques. Seeking data science or analyst roles to apply expertise in solving real-world problems through data-driven solutions. Holds a Master's degree in Information Systems with a focus on Big Data Analytics. Previous experience includes roles at Georgia State University, TeleSpecialists LLC, and Accenture Solutions. Has completed certifications in data visualization, Python, SQL, and NLP, and has received awards for outstanding performance.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "output_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvUq5uOWT0Ff"
      },
      "source": [
        "## Summarizing Large Documents Using Map Reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G3Eq6kDT0Ff"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5QxfLXGT0Ff"
      },
      "outputs": [],
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('Akhil_Golla_Resume8.pdf')\n",
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ixoZXN8T0Ff"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99Hg3eZBT0Ff",
        "outputId": "71902f55-3be4-4812-ec9f-956e7ec78416"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1819"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "llm.get_num_tokens(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEq45pGxT0Ff"
      },
      "outputs": [],
      "source": [
        "## Splittting the text\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "chunks = text_splitter.create_documents([text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYR-jvaHT0Ff",
        "outputId": "c708eb0c-7e3d-423a-c2c7-26a5a69cda16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6bAyLQ0T0Ff"
      },
      "outputs": [],
      "source": [
        "chain = load_summarize_chain(\n",
        "    llm,\n",
        "    chain_type='map_reduce',\n",
        "    verbose=False\n",
        ")\n",
        "summary = chain.run(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "7aIrHuNlT0Ff",
        "outputId": "ce0aa4b5-5a25-481c-9da1-2b8e6ee10296"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Akhil Golla is a Research Data Analyst with expertise in healthcare, cybersecurity, fraud analysis, and sales forecasting. They have experience in Python, SQL, R, machine learning techniques, data visualization tools, and cloud technologies. They have worked on projects involving web scraping, NLP, sentiment analysis, forecasting models, and neural networks. They have also implemented automation, improved data quality, and achieved high accuracy in predicting customer churn. They have received certifications in Power BI, Python for Data Science, SQL, and NLP, and have been recognized with awards for their work.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xttkJXD0T0Fg"
      },
      "source": [
        "## Map Reduce With Custom Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXjLK4paT0Fh"
      },
      "outputs": [],
      "source": [
        "chunks_prompt=\"\"\"\n",
        "Please summarize the below speech:\n",
        "Speech:`{text}'\n",
        "Summary:\n",
        "\"\"\"\n",
        "map_prompt_template=PromptTemplate(input_variables=['text'],\n",
        "                                    template=chunks_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApYU2OmFT0Fh"
      },
      "outputs": [],
      "source": [
        "final_combine_prompt='''\n",
        "Provide a final summary of the entire speech with these important points.\n",
        "Add a Generic Motivational Title,\n",
        "Start the precise summary with an introduction and provide the\n",
        "summary in number points for the speech.\n",
        "Speech: `{text}`\n",
        "'''\n",
        "final_combine_prompt_template=PromptTemplate(input_variables=['text'],\n",
        "                                             template=final_combine_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CpATN_mT0Fh"
      },
      "outputs": [],
      "source": [
        "summary_chain = load_summarize_chain(\n",
        "    llm=llm,\n",
        "    chain_type='map_reduce',\n",
        "    map_prompt=map_prompt_template,\n",
        "    combine_prompt=final_combine_prompt_template,\n",
        "    verbose=False\n",
        ")\n",
        "output = summary_chain.run(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "RXNfNW04T0Fh",
        "outputId": "526a2329-e31d-470d-a5a4-e157fcd405f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Title: Empowering Through Data: A Journey of Innovation and Impact\\n\\n1. Akhil Golla is a skilled Research Data Analyst with expertise in healthcare, cybersecurity, fraud analysis, sales forecasting, and predictive modeling, seeking roles to apply data-driven solutions.\\n2. The speaker has experience in machine learning techniques, data visualization tools, cloud technologies, and developer tools, with a focus on automating data collection and analysis.\\n3. Utilizing web scraping, NLP techniques, sentiment analysis, and OCR automation, the speaker improved decision-making efficiency, analysis efficiency, and forecasting accuracy in various projects.\\n4. The speaker implemented technological solutions to improve operational efficiency in physician scheduling, clinical note summarization, and data platform connections, resulting in significant cost savings and improved decision-making processes.\\n5. Achievements as an Associate Data Scientist include reducing financial losses, improving model transparency, optimizing data processing efficiency, and empowering leadership to make data-driven decisions.\\n6. As a Data Science Intern, the speaker increased monthly sales, improved stakeholder decision-making, and streamlined data analysis workflows through regression machine learning models, Tableau dashboards, and ETL pipelines.\\n7. Through automation of data processing tasks, preprocessing large datasets, and working on various data science projects, the speaker has increased efficiency, accuracy, and user engagement.\\n8. The speaker achieved a high accuracy rate in predicting customer churn, completed certifications in data science and machine learning courses, received awards for outstanding performance, and achieved a certification in the DOMO BI Tool.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmIQeXbdT0Fi"
      },
      "source": [
        "## RefineChain For Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OktCfp_xT0Fi",
        "outputId": "5c876236-aee1-40c1-8fae-aabbae32301c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"Akhil Golla\n",
            "404-934-1623 |akhilgolla08@gmail.com |LinkedIn |GitHub |Atlanta, GA (Open to relocation)\n",
            "Summary\n",
            "Currently working as a Research Data Analyst for the Georgia State University Cybersecurity Research Group,\n",
            "with prior experience as a Data Scientist in healthcare and 4+ years in cybersecurity, fraud analysis,\n",
            "sales forecasting, predictive modeling, Generative AI (Gen AI) , and Large Language Models (LLMs) .\n",
            "Immediate joiner seeking data science or analyst roles to leverage my expertise in solving real-world\n",
            "problems through data-driven solutions.\n",
            "Education\n",
            "Georgia State University Atlanta, GA\n",
            "Master of Science in Information Systems, Big Data Analytics Jan 2023 – Dec 2023\n",
            "Osmania Unversity Hyderabad, India\n",
            "Bachelor of Engineering, Electronics Jun 2016 – Sept 2020\n",
            "Technical Skills\n",
            "Programming Languages : Python, SQL, R, Pyspark.\n",
            "Python Libraries : Pandas, NumPy, Scikit-learn, TensorFlow, Keras, PyTorch, NLTK, Gensim, Matplotlib, Seaborn.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: Akhil Golla is a Research Data Analyst with experience in healthcare, cybersecurity, fraud analysis, and sales forecasting. He has expertise in Python, SQL, R, and various libraries for data analysis and modeling. He is seeking data science or analyst roles to apply his skills in solving real-world problems through data-driven solutions.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "Machine Learning : Linear-Logistic Regression, Decision Trees, Support Vector Machines, KNN, Random Forest,\n",
            "Clustering (K-means), Ensemble Modelling Techniques (Boosting, Stacking, Bagging), XGBoost, LightGBM, AdaBoost,\n",
            "Deep Learning, Large Language Models (LLM), Langchain, Transformers (BERT, BART, GPT), Neural\n",
            "Networks,LSTM, CNN, RNN, NLP, SARIMA, ARIMA, Prophet, OCR.\n",
            "Data Visualization Tools : Tableau, Microsoft Power BI, DOMO.\n",
            "Databases : Microsoft SQL Server, MySQL, Snowflake.\n",
            "Cloud Technologies : Databricks, AWS EC2, IAM, S3, Lambda, SageMaker, Glue.\n",
            "Developer Tools : Jupyter Notebook, Databricks, Alteryx, Git, VScode, Anaconda, Eclipse, Docker, Azure Data\n",
            "Studio, Salesforce.\n",
            "Experience\n",
            "Research Data Analyst Feb 2023 – Present\n",
            "Evidence-Based Cybersecurity Research Group – Georgia State University Atlanta, GA\n",
            "•Developed and maintained Python scripts using the Beautiful Soup library for automating data collection by\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: Akhil Golla is a Research Data Analyst with expertise in healthcare, cybersecurity, fraud analysis, and sales forecasting. He is skilled in Python, SQL, R, and various data analysis and modeling libraries. Akhil is seeking data science or analyst roles to apply his skills in solving real-world problems through data-driven solutions. He also has experience in machine learning techniques such as Linear-Logistic Regression, Decision Trees, Support Vector Machines, and Deep Learning. Additionally, he is proficient in data visualization tools like Tableau and Microsoft Power BI, as well as databases like Microsoft SQL Server and MySQL. Akhil has experience with cloud technologies such as Databricks and AWS, and developer tools like Jupyter Notebook and Git.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "web scraping multiple illicit Telegram channels, improving efficiency and saving 75% of time compared to manual\n",
            "processes by enabling automated and reusable scraping workflows.\n",
            "•Analyzed unstructured chat data from multiple channels and created impactful visualizations in Tableau ,\n",
            "enabling stakeholders to make informed decisions 50% faster and improving operational efficiency.\n",
            "•Designed and implemented an automated BERT-based classifier to detect theft-related and illegal transactions\n",
            "from Telegram and darknet data, achieving over 90% accuracy and contributing to public reporting of savings\n",
            "exceeding $10 million .\n",
            "•Created an automated chatbot using Python ,Selenium , and Wit AI to generate automatic responses across 20\n",
            "teen chat rooms, enabling data collection for an online honeypot awareness project, which contributed to\n",
            "safeguarding millions of teens from potential online threats.\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: Akhil Golla is a Research Data Analyst with expertise in healthcare, cybersecurity, fraud analysis, and sales forecasting. He is skilled in Python, SQL, R, and various data analysis and modeling libraries. Akhil is seeking data science or analyst roles to apply his skills in solving real-world problems through data-driven solutions. He also has experience in machine learning techniques such as Linear-Logistic Regression, Decision Trees, Support Vector Machines, and Deep Learning. Additionally, he is proficient in data visualization tools like Tableau and Microsoft Power BI, as well as databases like Microsoft SQL Server and MySQL. Akhil has experience with cloud technologies such as Databricks and AWS, and developer tools like Jupyter Notebook and Git. Akhil has also demonstrated his ability to improve efficiency through automated web scraping processes, create impactful visualizations for faster decision-making, implement classifiers for detecting illegal transactions, and develop chatbots for data collection and online safety projects.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "•Leveraged NLP techniques such as TF-IDF andsentiment analysis to extract key insights, popular content,\n",
            "and contextual patterns from Telegram channels, enhancing channel dynamics understanding and enabling\n",
            "actionable insights. This analysis improved decision-making efficiency by 40% for stakeholders addressing critical\n",
            "channel activities.\n",
            "•Designed and implemented an automated Python solution utilizing OCR (Optical Character Recognition) to\n",
            "detect and eliminate image duplication, achieving a 50% improvement in analysis efficiency. Integrated the\n",
            "solution with the Dropbox API to streamline data management and ensure seamless processing.Data Scientist March 2024 – November 2024\n",
            "TeleSpecialists LLC (Hospitals & Health Care) Atlanta, GA\n",
            "•Developed, scaled, and deployed a time series forecasting model using SARIMA to predict future case\n",
            "volumes from each facility and state. This enabled the company to proactively plan resources and optimize\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: Akhil Golla is a Research Data Analyst with expertise in healthcare, cybersecurity, fraud analysis, and sales forecasting. He is skilled in Python, SQL, R, and various data analysis and modeling libraries. Akhil is seeking data science or analyst roles to apply his skills in solving real-world problems through data-driven solutions. He also has experience in machine learning techniques such as Linear-Logistic Regression, Decision Trees, Support Vector Machines, and Deep Learning. Additionally, he is proficient in data visualization tools like Tableau and Microsoft Power BI, as well as databases like Microsoft SQL Server and MySQL. Akhil has experience with cloud technologies such as Databricks and AWS, and developer tools like Jupyter Notebook and Git. Akhil has also demonstrated his ability to improve efficiency through automated web scraping processes, create impactful visualizations for faster decision-making, implement classifiers for detecting illegal transactions, and develop chatbots for data collection and online safety projects. Akhil has leveraged NLP techniques and sentiment analysis to extract key insights from Telegram channels, improving decision-making efficiency by 40%. He also designed and implemented an automated Python solution using OCR to detect and eliminate image duplication, achieving a 50% improvement in analysis efficiency. Additionally, Akhil developed a time series forecasting model using SARIMA to predict future case volumes, enabling proactive resource planning and optimization for TeleSpecialists LLC.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "physician scheduling, leading to an 80% increase in operational efficiency by accurately forecasting volumes in\n",
            "advance.\n",
            "•Built an LSTM neural network ML model to forecast physician scheduling based on predicted case volumes,\n",
            "optimizing resource allocation, reducing scheduling conflicts, and saving $1 million annually by preventing\n",
            "overpayments to underutilized physicians.\n",
            "•Worked on developing a clinical note summarization system leveraging the BioBART large language\n",
            "model (LLM) to process over 1 million cases , significantly reducing the time required for physicians to revisit\n",
            "and review cases, improving workflow efficiency and enhancing patient care outcomes.\n",
            "•Created dynamic Tableau dashboards to visualize key metrics across departments including Physician\n",
            "Credentialing, Marketing, Medical Staff Division, Onboarding, IT, and HR. These dashboards delivered actionable\n",
            "insights, enhancing decision-making processes by 40% and improving operational outcomes.\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: Akhil Golla is a Research Data Analyst with expertise in healthcare, cybersecurity, fraud analysis, and sales forecasting. He is skilled in Python, SQL, R, and various data analysis and modeling libraries. Akhil is seeking data science or analyst roles to apply his skills in solving real-world problems through data-driven solutions. He also has experience in machine learning techniques such as Linear-Logistic Regression, Decision Trees, Support Vector Machines, and Deep Learning. Additionally, he is proficient in data visualization tools like Tableau and Microsoft Power BI, as well as databases like Microsoft SQL Server and MySQL. Akhil has experience with cloud technologies such as Databricks and AWS, and developer tools like Jupyter Notebook and Git. Akhil has also demonstrated his ability to improve efficiency through automated web scraping processes, create impactful visualizations for faster decision-making, implement classifiers for detecting illegal transactions, and develop chatbots for data collection and online safety projects. Akhil has leveraged NLP techniques and sentiment analysis to extract key insights from Telegram channels, improving decision-making efficiency by 40%. He also designed and implemented an automated Python solution using OCR to detect and eliminate image duplication, achieving a 50% improvement in analysis efficiency. Additionally, Akhil developed a time series forecasting model using SARIMA to predict future case volumes, enabling proactive resource planning and optimization for TeleSpecialists LLC. Akhil also built an LSTM neural network ML model to forecast physician scheduling based on predicted case volumes, optimizing resource allocation, reducing scheduling conflicts, and saving $1 million annually by preventing overpayments to underutilized physicians. He worked on developing a clinical note summarization system leveraging the BioBART large language model (LLM) to process over 1 million cases, significantly reducing the time required for physicians to revisit and review cases, improving workflow efficiency and enhancing patient care outcomes. Akhil also created dynamic Tableau dashboards to visualize key metrics across departments, delivering actionable insights, enhancing decision-making processes by 40%, and improving operational outcomes.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "•Established and managed connections between Tableau ,Salesforce ,Five9 , and SQL Server , streamlining data\n",
            "flow and enabling real-time access to processed data. This reduced reporting delays by 50% , enhancing analysis\n",
            "speed and efficiency.\n",
            "•Utilized Azure Data Studio to write SQL queries , extracting and preparing datasets for dashboards and\n",
            "reports. This improved data accuracy and reporting timelines by 30% across multiple departments.\n",
            "•Designed and maintained ETL pipelines to integrate patient case data with key metrics seamlessly, enabling\n",
            "accurate analysis and reporting. This streamlined hospital decision-making processes and reduced manual data\n",
            "processing efforts by 45% .\n",
            "Data Science Intern June 2023 – December 2023\n",
            "Elevance Health Inc. (formerly Anthem Inc.) Atlanta, GA\n",
            "•Developed a claim price prediction model using Random Forest andDecision Tree algorithms with\n",
            "ensemble stacking , achieving an R²score of 0.92 . This enhanced accuracy helped identify and mitigate claim\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: Akhil Golla is a Research Data Analyst with expertise in healthcare, cybersecurity, fraud analysis, and sales forecasting. He is skilled in Python, SQL, R, and various data analysis and modeling libraries. Akhil is seeking data science or analyst roles to apply his skills in solving real-world problems through data-driven solutions. He also has experience in machine learning techniques such as Linear-Logistic Regression, Decision Trees, Support Vector Machines, and Deep Learning. Additionally, he is proficient in data visualization tools like Tableau and Microsoft Power BI, as well as databases like Microsoft SQL Server and MySQL. Akhil has experience with cloud technologies such as Databricks and AWS, and developer tools like Jupyter Notebook and Git. Akhil has also demonstrated his ability to improve efficiency through automated web scraping processes, create impactful visualizations for faster decision-making, implement classifiers for detecting illegal transactions, and develop chatbots for data collection and online safety projects. Akhil has leveraged NLP techniques and sentiment analysis to extract key insights from Telegram channels, improving decision-making efficiency by 40%. He also designed and implemented an automated Python solution using OCR to detect and eliminate image duplication, achieving a 50% improvement in analysis efficiency. Additionally, Akhil developed a time series forecasting model using SARIMA to predict future case volumes, enabling proactive resource planning and optimization for TeleSpecialists LLC. Akhil also built an LSTM neural network ML model to forecast physician scheduling based on predicted case volumes, optimizing resource allocation, reducing scheduling conflicts, and saving $1 million annually by preventing overpayments to underutilized physicians. He established and managed connections between Tableau, Salesforce, Five9, and SQL Server, streamlining data flow and enabling real-time access to processed data, reducing reporting delays by 50% and enhancing analysis speed and efficiency. Akhil utilized Azure Data Studio to write SQL queries, extracting and preparing datasets for dashboards and reports, improving data accuracy and reporting timelines by 30% across multiple departments. He designed and maintained ETL pipelines to integrate patient case data with key metrics seamlessly, enabling accurate analysis and reporting, streamlining hospital decision-making processes, and reducing manual data processing efforts by 45%. As a Data Science Intern at Elevance Health Inc. (formerly Anthem Inc.) in Atlanta, GA, Akhil developed a claim price prediction model using Random Forest and Decision Tree algorithms with ensemble stacking, achieving an R² score of 0.92, enhancing accuracy to identify and mitigate claim issues.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "discrepancies, reducing financial losses by 50% and saving millions annually .\n",
            "•Maintained and managed machine learning models deployed in Docker environments , resolving\n",
            "environment-related issues and ensuring consistent model performance and reliability across production systems.\n",
            "•Improved model transparency by implementing SHAP andLIME for interpretability, enabling seamless\n",
            "communication of insights to non-technical stakeholders and fostering informed decision-making.\n",
            "•Optimized data processing efficiency by 40% through advanced SQL queries inSnowflake , enabling faster data\n",
            "management workflows and enhancing training processes for machine learning models.\n",
            "•Created interactive Tableau dashboards to track and analyze claim trends, visualize key performance metrics,\n",
            "and uncover patterns in claim overpayments. These dashboards empowered leadership to make data-driven\n",
            "decisions and adopt more strategic claims management practices.\n",
            "Associate Data Scientist January 2021 – December 2022\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: Akhil Golla is a Research Data Analyst with expertise in healthcare, cybersecurity, fraud analysis, and sales forecasting. He is skilled in Python, SQL, R, and various data analysis and modeling libraries. Akhil is seeking data science or analyst roles to apply his skills in solving real-world problems through data-driven solutions. He also has experience in machine learning techniques such as Linear-Logistic Regression, Decision Trees, Support Vector Machines, and Deep Learning. Additionally, he is proficient in data visualization tools like Tableau and Microsoft Power BI, as well as databases like Microsoft SQL Server and MySQL. Akhil has experience with cloud technologies such as Databricks and AWS, and developer tools like Jupyter Notebook and Git. Akhil has also demonstrated his ability to improve efficiency through automated web scraping processes, create impactful visualizations for faster decision-making, implement classifiers for detecting illegal transactions, and develop chatbots for data collection and online safety projects. Akhil has leveraged NLP techniques and sentiment analysis to extract key insights from Telegram channels, improving decision-making efficiency by 40%. He also designed and implemented an automated Python solution using OCR to detect and eliminate image duplication, achieving a 50% improvement in analysis efficiency. Additionally, Akhil developed a time series forecasting model using SARIMA to predict future case volumes, enabling proactive resource planning and optimization for TeleSpecialists LLC. Akhil also built an LSTM neural network ML model to forecast physician scheduling based on predicted case volumes, optimizing resource allocation, reducing scheduling conflicts, and saving $1 million annually by preventing overpayments to underutilized physicians. He established and managed connections between Tableau, Salesforce, Five9, and SQL Server, streamlining data flow and enabling real-time access to processed data, reducing reporting delays by 50% and enhancing analysis speed and efficiency. Akhil utilized Azure Data Studio to write SQL queries, extracting and preparing datasets for dashboards and reports, improving data accuracy and reporting timelines by 30% across multiple departments. He designed and maintained ETL pipelines to integrate patient case data with key metrics seamlessly, enabling accurate analysis and reporting, streamlining hospital decision-making processes, and reducing manual data processing efforts by 45%. As a Data Science Intern at Elevance Health Inc. (formerly Anthem Inc.) in Atlanta, GA, Akhil developed a claim price prediction model using Random Forest and Decision Tree algorithms with ensemble stacking, achieving an R² score of 0.92, enhancing accuracy to identify and mitigate claim issues. Akhil also maintained and managed machine learning models deployed in Docker environments, resolving environment-related issues and ensuring consistent model performance and reliability across production systems. He improved model transparency by implementing SHAP and LIME for interpretability, optimized data processing efficiency by 40% through advanced SQL queries in Snowflake, and created interactive Tableau dashboards to track and analyze claim trends, visualize key performance metrics, and uncover patterns in claim overpayments, empowering leadership to make data-driven decisions and adopt more strategic claims management practices.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "Accenture Solutions Hyderabad, India\n",
            "•Increased monthly sales by 25% by developing regression machine learning models to accurately predict crude oil\n",
            "demand, leveraging Python’s machine learning libraries to analyze market trends and forecast pricing\n",
            "strategies.\n",
            "•Enhanced stakeholder decision-making by creating actionable Tableau dashboards that visualized customer\n",
            "behavior and sales trends, improving marketing and pricing strategies for key products.\n",
            "•Drove success in product launches by setting goals, forecasting outcomes, and tracking key performance\n",
            "metrics , ensuring consistent improvement in market trends analysis.\n",
            "•Streamlined data analysis workflows by building ETL pipelines using Alteryx , seamlessly integrating product\n",
            "data with sales metrics, and enabling critical insights during stakeholder presentations.\n",
            "Data Science Intern October 2020 – December 2020\n",
            "Splash Business Intelligence Hyderabad, India\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: Akhil Golla is a Research Data Analyst with expertise in healthcare, cybersecurity, fraud analysis, and sales forecasting. He is skilled in Python, SQL, R, and various data analysis and modeling libraries. Akhil is seeking data science or analyst roles to apply his skills in solving real-world problems through data-driven solutions. He also has experience in machine learning techniques such as Linear-Logistic Regression, Decision Trees, Support Vector Machines, and Deep Learning. Additionally, he is proficient in data visualization tools like Tableau and Microsoft Power BI, as well as databases like Microsoft SQL Server and MySQL. Akhil has experience with cloud technologies such as Databricks and AWS, and developer tools like Jupyter Notebook and Git. Akhil has also demonstrated his ability to improve efficiency through automated web scraping processes, create impactful visualizations for faster decision-making, implement classifiers for detecting illegal transactions, and develop chatbots for data collection and online safety projects. Akhil has leveraged NLP techniques and sentiment analysis to extract key insights from Telegram channels, improving decision-making efficiency by 40%. He also designed and implemented an automated Python solution using OCR to detect and eliminate image duplication, achieving a 50% improvement in analysis efficiency. Additionally, Akhil developed a time series forecasting model using SARIMA to predict future case volumes, enabling proactive resource planning and optimization for TeleSpecialists LLC. Akhil also built an LSTM neural network ML model to forecast physician scheduling based on predicted case volumes, optimizing resource allocation, reducing scheduling conflicts, and saving $1 million annually by preventing overpayments to underutilized physicians. He established and managed connections between Tableau, Salesforce, Five9, and SQL Server, streamlining data flow and enabling real-time access to processed data, reducing reporting delays by 50% and enhancing analysis speed and efficiency. Akhil utilized Azure Data Studio to write SQL queries, extracting and preparing datasets for dashboards and reports, improving data accuracy and reporting timelines by 30% across multiple departments. He designed and maintained ETL pipelines to integrate patient case data with key metrics seamlessly, enabling accurate analysis and reporting, streamlining hospital decision-making processes, and reducing manual data processing efforts by 45%. As a Data Science Intern at Elevance Health Inc. (formerly Anthem Inc.) in Atlanta, GA, Akhil developed a claim price prediction model using Random Forest and Decision Tree algorithms with ensemble stacking, achieving an R² score of 0.92, enhancing accuracy to identify and mitigate claim issues. Akhil also maintained and managed machine learning models deployed in Docker environments, resolving environment-related issues and ensuring consistent model performance and reliability across production systems. He improved model transparency by implementing SHAP and LIME for interpretability, optimized data processing efficiency by 40% through advanced SQL queries in Snowflake, and created interactive Tableau dashboards to track and analyze claim trends, visualize key performance metrics, and uncover patterns in claim overpayments, empowering leadership to make data-driven decisions and adopt more strategic claims management practices. Akhil also increased monthly sales by 25% at Accenture Solutions in Hyderabad, India, by developing regression machine learning models to predict crude oil demand accurately. He enhanced stakeholder decision-making by creating actionable Tableau dashboards that visualized customer behavior and sales trends, drove success in product launches by setting goals and tracking key performance metrics, and streamlined data analysis workflows by building ETL pipelines using Alteryx to integrate product data with sales metrics.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "•Reduced manual effort by 75% through the automation of critical data processing tasks using shell/bash\n",
            "scripting , significantly improving operational efficiency.\n",
            "•Boosted data quality and availability by 30% by preprocessing large datasets using MySQL , including data\n",
            "cleaning, validation, and transformation, ensuring faster and more accurate insights for the data science team to act\n",
            "upon.Projects\n",
            "Text Summarization and Analysis with LangChain (LLM)\n",
            "•Enhanced document summarization efficiency by40% by leveraging advanced language model algorithms\n",
            "integrated with LangChain , enabling faster processing and analysis of large-scale text datasets.\n",
            "Predictive Analytics on Stack Exchange Data\n",
            "•Improved user engagement by 30% through the implementation of a Random Forest predictive model that\n",
            "accurately forecasted post responses and view counts, providing actionable insights to optimize content visibility.\n",
            "Telecom Customer Churn Prediction\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: Akhil Golla is a skilled Research Data Analyst with expertise in healthcare, cybersecurity, fraud analysis, and sales forecasting. He is proficient in Python, SQL, R, and various data analysis and modeling libraries. Akhil is seeking data science or analyst roles to apply his skills in solving real-world problems through data-driven solutions. He has experience in machine learning techniques such as Linear-Logistic Regression, Decision Trees, Support Vector Machines, and Deep Learning. Additionally, he is proficient in data visualization tools like Tableau and Microsoft Power BI, as well as databases like Microsoft SQL Server and MySQL. Akhil has experience with cloud technologies such as Databricks and AWS, and developer tools like Jupyter Notebook and Git. He has demonstrated his ability to improve efficiency through automated web scraping processes, create impactful visualizations for faster decision-making, implement classifiers for detecting illegal transactions, and develop chatbots for data collection and online safety projects. Akhil has leveraged NLP techniques and sentiment analysis to extract key insights from Telegram channels, improving decision-making efficiency by 40%. He also designed and implemented an automated Python solution using OCR to detect and eliminate image duplication, achieving a 50% improvement in analysis efficiency. Additionally, Akhil developed a time series forecasting model using SARIMA to predict future case volumes, enabling proactive resource planning and optimization for TeleSpecialists LLC. Akhil also built an LSTM neural network ML model to forecast physician scheduling based on predicted case volumes, optimizing resource allocation, reducing scheduling conflicts, and saving $1 million annually by preventing overpayments to underutilized physicians. He established and managed connections between Tableau, Salesforce, Five9, and SQL Server, streamlining data flow and enabling real-time access to processed data, reducing reporting delays by 50% and enhancing analysis speed and efficiency. Akhil utilized Azure Data Studio to write SQL queries, extracting and preparing datasets for dashboards and reports, improving data accuracy and reporting timelines by 30% across multiple departments. He designed and maintained ETL pipelines to integrate patient case data with key metrics seamlessly, enabling accurate analysis and reporting, streamlining hospital decision-making processes, and reducing manual data processing efforts by 45%. As a Data Science Intern at Elevance Health Inc. (formerly Anthem Inc.) in Atlanta, GA, Akhil developed a claim price prediction model using Random Forest and Decision Tree algorithms with ensemble stacking, achieving an R² score of 0.92, enhancing accuracy to identify and mitigate claim issues. Akhil also maintained and managed machine learning models deployed in Docker environments, resolving environment-related issues and ensuring consistent model performance and reliability across production systems. He improved model transparency by implementing SHAP and LIME for interpretability, optimized data processing efficiency by 40% through advanced SQL queries in Snowflake, and created interactive Tableau dashboards to track and analyze claim trends, visualize key performance metrics, and uncover patterns in claim overpayments, empowering leadership to make data-driven decisions and adopt more strategic claims management practices. Akhil also increased monthly sales by 25% at Accenture Solutions in Hyderabad, India, by developing regression machine learning models to predict crude oil demand accurately. He enhanced stakeholder decision-making by creating actionable Tableau dashboards that visualized customer behavior and sales trends, drove success in product launches by setting goals and tracking key performance metrics, and streamlined data analysis workflows by building ETL pipelines using Alteryx to integrate product data with sales metrics. Akhil also reduced manual effort by 75% through the automation of critical data processing tasks using shell/bash scripting, significantly improving operational efficiency. He boosted data quality and availability by 30% by preprocessing large datasets using MySQL, including data cleaning, validation, and transformation, ensuring faster and more accurate insights for the data science team to act upon. Akhil also enhanced document summarization efficiency by 40% by leveraging advanced language model algorithms integrated with LangChain, enabling faster processing and analysis of large-scale text datasets. Additionally, he improved user engagement by 30% through the implementation of a Random Forest predictive model that accurately forecasted post responses and view counts on Stack Exchange, providing actionable insights to optimize content visibility.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "•Achieved 94.33% accuracy in predicting customer churn by analyzing over 7,000 records using advanced\n",
            "machine learning techniques , including decision trees, random forests, and gradient boosting, resulting in\n",
            "targeted retention strategies and improved customer satisfaction.\n",
            "Certifications & Achievements\n",
            "•Completed certifications on Visualizing Data with Power BI (Udemy), Python for Data Science and\n",
            "Machine Learning (Udemy), SQL Bootcamp (Udemy), and NLP (Udemy).\n",
            "•Recognized with the “Rookie Star” award for outstanding performance at Accenture Solutions.\n",
            "•Achieved DOMO BI Tool Student Certification , demonstrating proficiency in business intelligence tools.\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "chain = load_summarize_chain(\n",
        "    llm=llm,\n",
        "    chain_type='refine',\n",
        "    verbose=True\n",
        ")\n",
        "output_summary = chain.run(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "KfVInYMeT0Fi",
        "outputId": "b3877e5f-d650-455c-9a12-540cf9626c10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Akhil Golla is a skilled Research Data Analyst with expertise in healthcare, cybersecurity, fraud analysis, and sales forecasting. He is proficient in Python, SQL, R, and various data analysis and modeling libraries. Akhil is seeking data science or analyst roles to apply his skills in solving real-world problems through data-driven solutions. He has experience in machine learning techniques such as Linear-Logistic Regression, Decision Trees, Support Vector Machines, and Deep Learning. Additionally, he is proficient in data visualization tools like Tableau and Microsoft Power BI, as well as databases like Microsoft SQL Server and MySQL. Akhil has experience with cloud technologies such as Databricks and AWS, and developer tools like Jupyter Notebook and Git. He has demonstrated his ability to improve efficiency through automated web scraping processes, create impactful visualizations for faster decision-making, implement classifiers for detecting illegal transactions, and develop chatbots for data collection and online safety projects. Akhil has leveraged NLP techniques and sentiment analysis to extract key insights from Telegram channels, improving decision-making efficiency by 40%. He also designed and implemented an automated Python solution using OCR to detect and eliminate image duplication, achieving a 50% improvement in analysis efficiency. Additionally, Akhil developed a time series forecasting model using SARIMA to predict future case volumes, enabling proactive resource planning and optimization for TeleSpecialists LLC. Akhil also built an LSTM neural network ML model to forecast physician scheduling based on predicted case volumes, optimizing resource allocation, reducing scheduling conflicts, and saving $1 million annually by preventing overpayments to underutilized physicians. He established and managed connections between Tableau, Salesforce, Five9, and SQL Server, streamlining data flow and enabling real-time access to processed data, reducing reporting delays by 50% and enhancing analysis speed and efficiency. Akhil utilized Azure Data Studio to write SQL queries, extracting and preparing datasets for dashboards and reports, improving data accuracy and reporting timelines by 30% across multiple departments. He designed and maintained ETL pipelines to integrate patient case data with key metrics seamlessly, enabling accurate analysis and reporting, streamlining hospital decision-making processes, and reducing manual data processing efforts by 45%. As a Data Science Intern at Elevance Health Inc. (formerly Anthem Inc.) in Atlanta, GA, Akhil developed a claim price prediction model using Random Forest and Decision Tree algorithms with ensemble stacking, achieving an R² score of 0.92, enhancing accuracy to identify and mitigate claim issues. Akhil also maintained and managed machine learning models deployed in Docker environments, resolving environment-related issues and ensuring consistent model performance and reliability across production systems. He improved model transparency by implementing SHAP and LIME for interpretability, optimized data processing efficiency by 40% through advanced SQL queries in Snowflake, and created interactive Tableau dashboards to track and analyze claim trends, visualize key performance metrics, and uncover patterns in claim overpayments, empowering leadership to make data-driven decisions and adopt more strategic claims management practices. Akhil also increased monthly sales by 25% at Accenture Solutions in Hyderabad, India, by developing regression machine learning models to predict crude oil demand accurately. He enhanced stakeholder decision-making by creating actionable Tableau dashboards that visualized customer behavior and sales trends, drove success in product launches by setting goals and tracking key performance metrics, and streamlined data analysis workflows by building ETL pipelines using Alteryx to integrate product data with sales metrics. Akhil also reduced manual effort by 75% through the automation of critical data processing tasks using shell/bash scripting, significantly improving operational efficiency. He boosted data quality and availability by 30% by preprocessing large datasets using MySQL, including data cleaning, validation, and transformation, ensuring faster and more accurate insights for the data science team to act upon. Akhil also enhanced document summarization efficiency by 40% by leveraging advanced language model algorithms integrated with LangChain, enabling faster processing and analysis of large-scale text datasets. Additionally, he improved user engagement by 30% through the implementation of a Random Forest predictive model that accurately forecasted post responses and view counts on Stack Exchange, providing actionable insights to optimize content visibility. Akhil achieved 94.33% accuracy in predicting customer churn by analyzing over 7,000 records using advanced machine learning techniques, including decision trees, random forests, and gradient boosting, resulting in targeted retention strategies and improved customer satisfaction. He has completed certifications on Visualizing Data with Power BI, Python for Data Science and Machine Learning, SQL Bootcamp, and NLP. Akhil has been recognized with the \"Rookie Star\" award for outstanding performance at Accenture Solutions and has achieved DOMO BI Tool Student Certification, demonstrating proficiency in business intelligence tools.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "output_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vyOGQfZT0Fi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}